app = 'llm-framework-prod'
primary_region = 'dfw'

[build]
  builder = 'heroku/buildpacks:20'
  buildpacks = ['heroku/nodejs']

[env]
  NODE_ENV = 'production'
  PORT = '8080'
  DASHBOARD_PORT = '8081'
  MCP_PORT = '3001'
  WS_PORT = '8082'

[[services]]
  protocol = 'tcp'
  internal_port = 8080
  processes = ['app']

  [[services.ports]]
    port = 80
    handlers = ['http']
    force_https = true

  [[services.ports]]
    port = 443
    handlers = ['http', 'tls']

  [services.concurrency]
    type = 'connections'
    hard_limit = 1000
    soft_limit = 800

  [[services.tcp_checks]]
    interval = '15s'
    timeout = '2s'
    grace_period = '10s'

  [[services.http_checks]]
    interval = '30s'
    timeout = '5s'
    grace_period = '15s'
    method = 'get'
    path = '/health'
    protocol = 'http'
    tls_skip_verify = false

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 1
  processes = ['app']

[[vm]]
  cpu_kind = 'shared'
  cpus = 2
  memory_mb = 1024

[metrics]
  port = 9091
  path = '/metrics'

[deploy]
  release_command = 'npm run build'
  strategy = 'canary'

[processes]
  app = 'npm start'
app = "llm-ai-bridge"
primary_region = "sjc"

[build]
  dockerfile = "Dockerfile"

[deploy]
  strategy = "rolling"

[env]
  NODE_ENV = "production"
  PORT = "8080"
  AI_BRIDGE_HISTORY_LIMIT = "1000"
  AI_BRIDGE_MAX_QUEUE = "2000"
  AI_BRIDGE_CORS_ORIGINS = "*"
  AI_BRIDGE_CLIENT_TTL_MS = "900000"
  AI_BRIDGE_CLEANUP_INTERVAL_MS = "60000"
  AI_BRIDGE_RATE_WINDOW_MS = "60000"
  AI_BRIDGE_RATE_MAX = "200"

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 0
  
  [[http_service.concurrency]]
    type = "connections"
    hard_limit = 1000
    soft_limit = 500
  
  [http_service.checks]
    grace_period = "30s"
    interval = "15s"
    method = "GET"
    path = "/health"
    timeout = "10s"
    headers = { "User-Agent" = "fly-health-check" }

[[vm]]
  cpu_kind = "shared"
  cpus = 1
  memory_mb = 512

[metrics]
  port = 9091
  path = "/metrics"